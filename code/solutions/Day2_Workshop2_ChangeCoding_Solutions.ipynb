{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655252d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Header: introduce dataset and goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11244721",
   "metadata": {},
   "source": [
    "![Image](../../resources/cropped-SummerWorkshop_Header.png)\n",
    "\n",
    "<h1 align=\"center\">Population Coding</h1> \n",
    "<h2 align=\"center\"> Day 2, Afternoon Session</h2> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f95c14",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "In the first workshop of today, we examined how sensory variables can be encoded in individual neurons' activity. We now turn our attention to the coordinated activity of groups of neurons: population codes!\n",
    "    \n",
    "### How do populations of neurons encode information about task-relevant sensory information? \n",
    "### How are these population codes modulated by task context or behavioral state? \n",
    "### What other types of thing are encoded in population activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace this section with the standard setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from allensdk.brain_observatory.behavior.behavior_project_cache.\\\n",
    "    behavior_neuropixels_project_cache \\\n",
    "    import VisualBehaviorNeuropixelsProjectCache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e49ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2024/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on CodeOcean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = VisualBehaviorNeuropixelsProjectCache.from_local_cache(cache_dir=data_root, use_static_cache=True)\n",
    "\n",
    "# get the metadata tables\n",
    "units_table = cache.get_unit_table()\n",
    "\n",
    "channels_table = cache.get_channel_table()\n",
    "\n",
    "probes_table = cache.get_probe_table()\n",
    "\n",
    "behavior_sessions_table = cache.get_behavior_session_table()\n",
    "\n",
    "ecephys_sessions_table = cache.get_ecephys_session_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e6aa9",
   "metadata": {},
   "source": [
    "## First, let's load data from a recording session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cache.get_ecephys_session(\n",
    "           ecephys_session_id=1065437523)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28561c",
   "metadata": {},
   "source": [
    "### The stimulus presentations table is a record of every stimulus we presented to the mouse over the course of this experiment. Let's take a look at this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations = session.stimulus_presentations\n",
    "stimulus_presentations.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0335b30",
   "metadata": {},
   "source": [
    "### It contains a great deal of information about the stimulus presentations! Let's look at all the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eae999",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6fce4f",
   "metadata": {},
   "source": [
    "### The different stimuli are indexed by the 'stimulus_block' column. Let's group this dataframe by stimulus block and see what stimulus was shown for each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations = session.stimulus_presentations\n",
    "stimulus_presentations.groupby('stimulus_block')[['stimulus_block', \n",
    "                                                'stimulus_name', \n",
    "                                                'active', \n",
    "                                                'duration', \n",
    "                                                'start_time']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc20e0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "What are the types of stimulus block that were presented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations['stimulus_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32b1ea",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "What stimuli were shown in the 'Natural_Images_Lum_Matched_set_ophys_G_2019' block?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations = session.stimulus_presentations\n",
    "stimulus_presentations = stimulus_presentations[stimulus_presentations.stimulus_name == 'Natural_Images_Lum_Matched_set_ophys_G_2019']\n",
    "stimulus_presentations.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(stimulus_presentations['image_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183d84a",
   "metadata": {},
   "source": [
    "### We'll also want some information about the mouse behavior! This is contained in the \"trials\" table. Let's take a quick look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f418d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = session.trials\n",
    "trials['change_time'] = trials['change_time_no_display_delay'] # a slightly easier name for this column\n",
    "\n",
    "trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc02d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef4290",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "How many trials are there and how many stimulus presentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d771d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} trials'.format(len(trials)))\n",
    "print('{} stimulus presentations'.format(len(stimulus_presentations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30810da7",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "What does the distribution of trial lengths look like? What does distribution of aborted trial lengths look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_bins = np.arange(0, 20, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(trials['trial_length'].values, bins=duration_bins, label='All trials')\n",
    "plt.xlabel('Trial length (seconds)')\n",
    "plt.ylabel('Number of trials')\n",
    "plt.title('All trials')\n",
    "\n",
    "plt.hist(trials['trial_length'].values[trials['aborted'].values], bins=duration_bins, label='Aborted trials', histtype='step', linewidth=4)\n",
    "plt.title('Aborted trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5175c",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">Now, how well does the mouse do the task? What are its hit, miss, and false alarm rates? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d02abc",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "The pre-computed false alarms and correct rejections are computed from \"catch\" trials, in which the image does not change at the scheduled change time. If the mouse licks before the change, the trial is aborted. This could also be called a false alarm. \n",
    "\n",
    "Note that the first few trials are auto-rewarded, and should not be counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d67e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_catch_trials = np.sum(trials['catch'].values)\n",
    "num_go_trials = len(trials) - np.sum(trials['auto_rewarded'].values) - num_catch_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2556e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aborted_trials = np.sum(trials['aborted'].values)\n",
    "\n",
    "print('Total trials: {}'.format(num_go_trials + num_catch_trials))\n",
    "print('Go trials: {}'.format(num_regular_trials))\n",
    "print('Aborted go trials: {}'.format(num_aborted_trials))\n",
    "print('Catch trials: {}'.format(num_catch_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hit rate: {}'.format(np.sum(trials['hit']) / num_go_trials ))\n",
    "print('Abort (false alarm) rate: {}'.format(num_aborted_trials / num_go_trials ))\n",
    "print('Miss rate: {}'.format(np.sum(trials['miss']) / num_go_trials ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7200e0",
   "metadata": {},
   "source": [
    "### Now let's get unit and channel data, sort the units by depth and filter for \"good\" units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get unit and channel data, sort the units by depth and filter for \"good\" units\n",
    "units = session.get_units() # contains information about spike waveforms, isolation quality\n",
    "channels = session.get_channels() # contains information about anatomical location\n",
    "\n",
    "unit_channels = units.merge(channels, left_on='peak_channel_id', right_index=True)\n",
    "\n",
    "#first let's sort our units by depth and filter\n",
    "unit_channels = unit_channels.sort_values('probe_vertical_position', ascending=False)\n",
    "\n",
    "#now we'll filter them\n",
    "good_unit_filter = ((unit_channels['snr']>1)&\n",
    "                    (unit_channels['isi_violations']<1)&\n",
    "                    (unit_channels['firing_rate']>0.1))\n",
    "\n",
    "good_units = unit_channels.loc[good_unit_filter]\n",
    "spike_times = session.spike_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd98a46",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    Which brain structures were recorded from in this session? How many units are present in each structure? (Hint: try the \"value_counts\" function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57950288",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_channels.value_counts('structure_acronym')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b3fec",
   "metadata": {},
   "source": [
    "### For now, let's look at the population activity in primary visual cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = 'VISp'\n",
    "area_units = good_units[good_units['structure_acronym'] == area_of_interest]\n",
    "num_units = len(area_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1add6",
   "metadata": {},
   "source": [
    "### Let's start by looking at the neural activity! Does it reflect the image presentation?\n",
    "\n",
    "### The session.spike_times object contains all spike times, in seconds, indexed by the unit ID. Let's take a look at this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = session.spike_times\n",
    "spike_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75dfcb",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "\n",
    "Get the array of spike times for unit 1068230173. How many times does this unit spike in the first minute of the experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_spike_times = spike_times[1068230173]\n",
    "unit_spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(unit_spike_times < 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90421fed",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "\n",
    "Plot a population spike raster spanning 1 second before to 1 second after a stimulus presentation. Fill in the code in the for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot a single-trial raster, population PSTH, and representation matrix\n",
    "pre_time = 1\n",
    "post_time = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "presentation_idx = 1\n",
    "start_time = stimulus_presentations['start_time'][presentation_idx] # in seconds - start one second before this\n",
    "end_time = stimulus_presentations['end_time'][presentation_idx] # in seconds - go to one second after this\n",
    "\n",
    "unit_num = 0\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]\n",
    "    \n",
    "    unit_spike_times = unit_spike_times[(unit_spike_times >= start_time - pre_time) * (unit_spike_times < end_time + post_time)]\n",
    "    unit_num_spikes = len(unit_spike_times)\n",
    "    \n",
    "    ax.plot(unit_spike_times - start_time, unit_num*np.ones(unit_num_spikes,), 'k|', markersize=5)\n",
    "    unit_num += 1\n",
    "\n",
    "ax.set_title('Single-trial raster')\n",
    "ax.set_xlabel('Time relative to stimulus presentation (s)')\n",
    "ax.set_ylabel('Unit')\n",
    "ax.set_ylim((0, num_units+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a4acf",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "Now let's compare to a change trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62007f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### plot a single-trial raster, population PSTH, and representation matrix\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "change_idx = np.where(stimulus_presentations['is_change'].values)[0]\n",
    "presentation_idx = change_idx[0]\n",
    "\n",
    "start_time = stimulus_presentations['start_time'][presentation_idx]\n",
    "end_time = stimulus_presentations['end_time'][presentation_idx]\n",
    "\n",
    "unit_num = 0\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]\n",
    "    \n",
    "    unit_spike_times = unit_spike_times[(unit_spike_times >= start_time - pre_time) * (unit_spike_times < end_time + post_time)]\n",
    "    unit_num_spikes = len(unit_spike_times)\n",
    "    \n",
    "    ax.plot(unit_spike_times - start_time, unit_num*np.ones(unit_num_spikes,), 'k|', markersize=5)\n",
    "    unit_num += 1\n",
    "\n",
    "ax.set_xlabel('Time relative to stimulus presentation (s)')\n",
    "ax.set_ylabel('Unit')\n",
    "ax.set_ylim((0, num_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465c256",
   "metadata": {},
   "source": [
    "### Now let's take a look at the trial-averaged responses to see how a neuron encodes the stimulus in its time-dependent firing rate (its peri-stimulus time histogram, or PSTH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convenience function to compute the PSTH\n",
    "def makePSTH(spikes, startTimes, windowDur, binSize=0.001):\n",
    "    bins = np.arange(0,windowDur+binSize,binSize)\n",
    "    counts = np.zeros(bins.size-1)\n",
    "    for i,start in enumerate(startTimes):\n",
    "        startInd = np.searchsorted(spikes, start)\n",
    "        endInd = np.searchsorted(spikes, start+windowDur)\n",
    "        counts = counts + np.histogram(spikes[startInd:endInd]-start, bins)[0]\n",
    "    \n",
    "    counts = counts/startTimes.size\n",
    "    return counts/binSize, bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4818c39",
   "metadata": {},
   "source": [
    "Let's start by plotting the response of unit 0 to one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = stimulus_presentations['image_name'].unique()\n",
    "stimulus = stimuli[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d103d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "presentations = stimulus_presentations[stimulus_presentations['image_name'] == stimulus]\n",
    "num_presentations = len(presentations)\n",
    "\n",
    "start_times = presentations['start_time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_ids = area_units.index\n",
    "iu = unit_ids[0]\n",
    "unit_spike_times = spike_times[iu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before_im = 1\n",
    "duration = 2\n",
    "\n",
    "unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                  start_times - time_before_im, \n",
    "                                  duration, binSize=0.01)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(bins[:-1] - time_before_im, unit_response)\n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa75e5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "Plot the PSTHs for every unit to that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a311e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a set of PSTHs\n",
    "\n",
    "psths = []\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]  \n",
    "    unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                      start_times - time_before_im, \n",
    "                                      duration, binSize=0.01)\n",
    "    \n",
    "    psths.append(unit_response)\n",
    "    ax.plot(bins[:-1]-time_before_im, unit_response)\n",
    "    \n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc0d5e",
   "metadata": {},
   "source": [
    "### We can see the trial structure of the task reflected in the PSTH. Some units have very strong transient responses to the image presentation. Do these responses depend on the task structure (whether the image is a change or not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c716e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "Plot the PSTHs for every unit to that image on change trials only. Are the same neurons the most responsive on change trials as on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3657630",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_start_times = start_times[presentations['is_change'].values.astype('bool')]\n",
    "\n",
    "psths = []\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]  \n",
    "    unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                      change_start_times - time_before_im, \n",
    "                                      duration, binSize=0.01)\n",
    "    \n",
    "    psths.append(unit_response)\n",
    "    ax.plot(bins[:-1]-time_before_im, unit_response)\n",
    "    \n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8389f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "Plot the PSTHs for every unit to another image on change trials. Do the same neurons have the strongest responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = stimuli[1]\n",
    "\n",
    "presentations = stimulus_presentations[stimulus_presentations['image_name'] == stimulus]\n",
    "start_times = presentations['start_time'].values\n",
    "change_start_times = start_times[presentations['is_change'].values.astype('bool')]\n",
    "\n",
    "num_presentations = len(presentations)\n",
    "\n",
    "start_times = presentations['start_time'].values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]  \n",
    "    unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                      start_times - time_before_im, \n",
    "                                      duration, binSize=0.01)\n",
    "    \n",
    "    psths.append(unit_response)\n",
    "    ax.plot(bins[:-1]-time_before_im, unit_response)\n",
    "    \n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091dd7ef",
   "metadata": {},
   "source": [
    "## Training a classifier on population spiking data\n",
    "Now we'll look at how the population activity encodes the image change. To determine how well we can decode the image change from population activity, we will train a **classifier** on a matrix of firing rates. Whereas regression models try to predict continuous values from the input features, classification models try to predict *labels* (also known as classes) from the input features.\n",
    "\n",
    "### Support Vector Machines\n",
    "\n",
    "Let's start with a linear Support Vector Machine (SVM) classifier, which will try to draw linear boundaries between orientation conditions (the labels) in our high-dimensional firing rate space.\n",
    "\n",
    "This cartoon shows how we would expect an SVM to behave on a dataset with two dimensions and three conditions:\n",
    "\n",
    "![SVM illustration](../../resources/svm-classifier.png)\n",
    "\n",
    "SVM computes decision boundaries in feature space that can be used to classify different conditions. If a new data point appears, the SVM classifier will label it based on where it falls with respect to these boundaries.\n",
    "\n",
    "To train an SVM, we need to import the following methods from `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f21c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2c41c",
   "metadata": {},
   "source": [
    "### First, we need to create a response matrix and vector of stimulus labels. It'll be convenient to have some of the trial-related information in the stimulus table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd4c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trials_id_to_stimulus_presentations(stimulus_presentations, trials):\n",
    "    \"\"\"\n",
    "    Add trials_id to stimulus presentations by finding the closest change time to each stimulus start time\n",
    "    If there is no corresponding change time, the trials_id is NaN\n",
    "    :param: stimulus_presentations: stimulus_presentations attribute of BehaviorOphysExperiment object, must have 'start_time'\n",
    "    :param trials: trials attribute of BehaviorOphysExperiment object, must have 'change_time'\n",
    "    \"\"\"\n",
    "    # for each stimulus_presentation, find the trials_id that is closest to the start time\n",
    "    # add to a new column called 'trials_id'\n",
    "    for idx, stimulus_presentation in stimulus_presentations.iterrows():\n",
    "        start_time = stimulus_presentation['start_time']\n",
    "        query_string = 'change_time > @start_time - 1 and change_time < @start_time + 1'\n",
    "        trials_id = (\n",
    "            np.abs(start_time - trials.query(query_string)['change_time']))\n",
    "        if len(trials_id) == 1:\n",
    "            trials_id = trials_id.idxmin()\n",
    "        else:\n",
    "            trials_id = np.nan\n",
    "        stimulus_presentations.loc[idx, 'trials_id'] = trials_id\n",
    "    return stimulus_presentations\n",
    "\n",
    "\n",
    "def add_trials_data_to_stimulus_presentations_table(stimulus_presentations, trials):\n",
    "    \"\"\"\n",
    "    Add trials_id to stimulus presentations table then join relevant columns of trials with stimulus_presentations\n",
    "    :param: stimulus_presentations: stimulus_presentations attribute of BehaviorOphysExperiment object, must have 'start_time'\n",
    "    :param trials: trials attribute of BehaviorOphysExperiment object, must have 'change_time'\n",
    "    \"\"\"\n",
    "    # add trials_id and merge to get trial type information\n",
    "    stimulus_presentations = add_trials_id_to_stimulus_presentations(\n",
    "        stimulus_presentations, trials)\n",
    "    # only keep certain columns\n",
    "    trials = trials[['change_time', 'go', 'catch', 'aborted', 'auto_rewarded',\n",
    "                     'hit', 'miss', 'false_alarm', 'correct_reject',\n",
    "                     'response_time', 'response_time', 'reward_time', 'reward_volume', ]]\n",
    "    # merge trials columns into stimulus_presentations\n",
    "    stimulus_presentations = stimulus_presentations.reset_index().merge(\n",
    "        trials, on='trials_id', how='left')\n",
    "    stimulus_presentations = stimulus_presentations.set_index(\n",
    "        'stimulus_presentations_id')\n",
    "    return stimulus_presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ecb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total trials: {}'.format(len(all_stimulus_presentations)))\n",
    "print('Change trials: {}'.format(np.sum(all_stimulus_presentations['is_change'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333bacfd",
   "metadata": {},
   "source": [
    "### The vast majority of stimulus presentations (~95%) are not a change. So a decoder could get 95% accuracy by predicting that there are no changes!\n",
    "\n",
    "To avoid this, we will balance the trials and decode change vs pre-change. We also don't want to include the 5 auto-rewarded trials at the beginning of the session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412473a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stimulus_presentations = session.stimulus_presentations\n",
    "\n",
    "trials = session.trials\n",
    "trials['change_time'] = trials['change_time_no_display_delay']\n",
    "\n",
    "# add pre-change\n",
    "all_stimulus_presentations['pre_change'] = all_stimulus_presentations['is_change'].shift(\n",
    "    -1)\n",
    "\n",
    "# add trials information to the stimulus presentations table\n",
    "all_stimulus_presentations = add_trials_id_to_stimulus_presentations(all_stimulus_presentations, trials)\n",
    "all_stimulus_presentations = add_trials_data_to_stimulus_presentations_table(all_stimulus_presentations, trials)\n",
    "\n",
    "# isolate the trials to use for decoding\n",
    "decode_trial_ind = (all_stimulus_presentations['is_change'].values + all_stimulus_presentations['pre_change'].values)\n",
    "stimulus_presentations = all_stimulus_presentations[decode_trial_ind]\n",
    "\n",
    "not_auto_rewarded_ind = [~a for a in stimulus_presentations['auto_rewarded'].values.astype('bool')]\n",
    "stimulus_presentations = stimulus_presentations[not_auto_rewarded_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b642a",
   "metadata": {},
   "source": [
    "### Now let's make our matrix of responses and vector of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_response_array(spike_times, stimulus_presentations, units, window=.05):\n",
    "\n",
    "    '''\n",
    "    Create an array of spike counts x stimulus presentations, and a corresponding list of stimulus label\n",
    "    spike_times: spike times \n",
    "    stimulus_presentation: stimulus presentation table\n",
    "    units: units table containing only the units to get the responses of\n",
    "    '''\n",
    "\n",
    "    # sort spike times chronologically; necessary for the binary search later\n",
    "    sorted_spikes = dict()\n",
    "    for iu in units.index:\n",
    "        # mergesort/timsort since most spike_times are already sorted\n",
    "        sorted_spikes[iu] = np.sort(spike_times[iu], kind='mergesort')\n",
    "\n",
    "    # create our own copy of stimulus presentations and sort by presentation start time chronologically\n",
    "    # sortation of stimulus_presentations isn't necessary, but it speeds up the vectorized `searchsorted(...)`\n",
    "    stimulus_presentations = stimulus_presentations.sort_values(by='start_time', kind='mergesort', inplace=False)\n",
    "\n",
    "    # Calculate the duration of stimulus presentations, and drop NaN durations\n",
    "    stimulus_presentations['duration'] = stimulus_presentations['end_time'] - stimulus_presentations['start_time']\n",
    "    stimulus_presentations.dropna(subset='duration', inplace=True)\n",
    "    \n",
    "    # Warn if window size is too big\n",
    "    if np.any(window > stimulus_presentations['duration']):\n",
    "        print('Warning: window size longer than stimulus presentation')\n",
    "\n",
    "    responses_by_unit = list()\n",
    "    for iu in units.index:\n",
    "        unit_spike_times = sorted_spikes[iu]\n",
    "\n",
    "        # Determine the first and last spike time for each stimulus presentation\n",
    "        start_is = np.searchsorted(unit_spike_times, stimulus_presentations['start_time'])\n",
    "        end_is = np.searchsorted(unit_spike_times, stimulus_presentations['start_time']+window)\n",
    "\n",
    "        # presentation_spike_times = unit_spike_times[start_i:end_i]\n",
    "\n",
    "        # Calculate the response rate for each stimulus presentation\n",
    "        responses_by_unit.append((end_is - start_is) / stimulus_presentations['duration'])\n",
    "\n",
    "    # responses_by_unit has each row a unit, and each column a stimulus, flip so that rows are stimuli\n",
    "    responses = np.transpose(responses_by_unit)\n",
    "\n",
    "    # Extract the labels that match the responses from our sorted stimulus presentations table\n",
    "    labels = np.array(stimulus_presentations['is_change']).astype('int')\n",
    "        \n",
    "    # Extract the mouse's behavioral response\n",
    "    hit = np.array(stimulus_presentations['hit']).astype('int')\n",
    "    miss = np.array(stimulus_presentations['miss']).astype('int')\n",
    "   \n",
    "    return responses, labels, hit, miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4284c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses, labels, hit, miss = make_response_array(spike_times, stimulus_presentations, area_units, window=.07)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a10fb5",
   "metadata": {},
   "source": [
    "### We will first select a random subset of trials for training the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778764ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_presentations = responses.shape[0]\n",
    "num_train = int(total_presentations * 0.5) # Use 50% of trials for training\n",
    "random_trial_order = np.random.permutation(responses.shape[0])\n",
    "train_indices = random_trial_order[:num_train]\n",
    "\n",
    "training_data = responses[train_indices]\n",
    "training_labels = labels[train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc65166",
   "metadata": {},
   "source": [
    "### Next, we'll create the model and fit it to our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2735d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(responses[train_indices], labels[train_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7ef93",
   "metadata": {},
   "source": [
    "### Now that our model has been trained, we can ask it to classify unlabeled data (i.e., the sets of population firing rates that were not included in our original training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b96247",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = random_trial_order[num_train:]\n",
    "test_data = responses[test_indices]\n",
    "predicted_labels = clf.predict(responses[test_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c260ff5d",
   "metadata": {},
   "source": [
    "### We can compare the predicted labels to the actual labels in order to assess the classifier's performance. We'll assess accuracy as the fraction of correctly predicted test images. As a baseline, we'll also compute the accuracy of a uniform random prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = np.unique(labels)\n",
    "\n",
    "actual_labels = labels[test_indices]\n",
    "accuracy = np.mean(actual_labels == predicted_labels)\n",
    "\n",
    "print('Accurary: {}'.format(accuracy))\n",
    "print('Chance level: {}'.format(1/len(conditions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbbe31",
   "metadata": {},
   "source": [
    "### We see that we perform better than chance! We can get a better sense of classification performance by using leave-one-out cross-validation. The `scikit-learn.model_selection.LeaveOneOut` iterator will automatically cycle through trials, on each iteration using one trial as a test and the others to train the classifier. Note that the model is fit independently on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b75b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "confusions = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "num_splits = 5\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)    \n",
    "#     print(accuracy)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize='pred'))\n",
    "    \n",
    "print(f\"\\nmean accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"chance: {1/conditions.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c31354",
   "metadata": {},
   "source": [
    "The leave-one-out cross-validation roughly agrees with our previous result. Do we do better on change or pre-change images? To assess this we'll look at the confusion matrix, which tells us how frequently each condition is predicted on change and pre-change presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusions, conditions, title=None):\n",
    "    \n",
    "    mean_confusion = np.mean(confusions, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    im = ax.imshow(mean_confusion, cmap='gray_r', clim=(0, 1))\n",
    "    plt.colorbar(im, ax=ax, label='Fraction of classifications')\n",
    "    \n",
    "    ax.set_xticks(range(len(conditions)), conditions, rotation=45)\n",
    "    ax.set_yticks(range(len(conditions)), conditions)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"Actual label\")\n",
    "    if title is None:\n",
    "        ax.set_title('Confusion Matrix')\n",
    "    elif type(title) is str:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "plot_confusion_matrix(confusions, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3a481",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "How does this V1-based decoder perform on hit trials vs miss trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e325d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "accuracies_hit = []\n",
    "accuracies_miss = []\n",
    "\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46753d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d56d5f",
   "metadata": {},
   "source": [
    "## Exploring the time course of image change-related information "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a1712",
   "metadata": {},
   "source": [
    "\n",
    "Next we'll examine the time course of information in our population! Or more specifically: how the length of the spike count window affects the decoding accuracy. Can we decode the stimulus perfectly if we integrate spikes for long enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa8734",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "First, let's try decoding with a longer response window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses, labels, hit, miss = make_response_array(spike_times, stimulus_presentations, area_units, window=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) \n",
    "\n",
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe5d8d",
   "metadata": {},
   "source": [
    "With a long response window we can discriminate change vs pre-change almost perfectly based on V1 activity!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18775f3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "How long do we need to integrate spikes in order to saturate the decoding performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_lengths = np.arange(.01, .2, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6705e",
   "metadata": {},
   "source": [
    "Here we'll use a relaxed, K-Fold cross-validation instead of LeaveOneOut for speed purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 10\n",
    "accuracies = np.zeros((len(window_lengths), num_splits))\n",
    "accuracies_hit = np.zeros((len(window_lengths), num_splits))\n",
    "accuracies_miss = np.zeros((len(window_lengths), num_splits))\n",
    "\n",
    "for i, window in enumerate(window_lengths):\n",
    "    print('{}/{}'.format(i, len(window_lengths)))\n",
    "    responses, labels, hit, miss = make_response_array(spike_times, stimulus_presentations, area_units, window)\n",
    "    \n",
    "    k = 0\n",
    "    for train_indices, test_indices in KFold(n_splits=num_splits, shuffle=True).split(responses):\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(responses[train_indices], labels[train_indices])\n",
    "\n",
    "        test_targets = labels[test_indices]\n",
    "        test_predictions = clf.predict(responses[test_indices])\n",
    "\n",
    "        accuracies[i, k] = np.mean(test_targets == test_predictions)        \n",
    "        \n",
    "        test_hit = hit[test_indices].astype('bool')\n",
    "        test_miss = miss[test_indices].astype('bool')\n",
    "        \n",
    "        accuracies_hit[i, k] = np.mean(test_targets[test_hit] == test_predictions[test_hit])\n",
    "        accuracies_miss[i, k] = np.mean(test_targets[test_miss] == test_predictions[test_miss])\n",
    "        \n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=window_lengths, y=accuracies.mean(axis=(1)), yerr=accuracies.std(axis=(1))/np.sqrt(num_splits), fmt='o-', label='all trials')\n",
    "plt.errorbar(x=window_lengths, y=accuracies_hit.mean(axis=(1)), yerr=accuracies_hit.std(axis=(1))/np.sqrt(num_splits), fmt='o-', label='hit trials')\n",
    "plt.errorbar(x=window_lengths, y=accuracies_miss.mean(axis=(1)), yerr=accuracies_miss.std(axis=(1))/np.sqrt(num_splits), fmt='o-', label='miss trials')\n",
    "\n",
    "plt.xlabel('Spike counting window length (s)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=0, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de494657",
   "metadata": {},
   "source": [
    "## Relationship between population size and decoding accuracy\n",
    "\n",
    "Next we'll examine how the size of the simultaneously recorded population affects decoding accuracy. In any physiology experiment, we only have a very small window into the overall population response. For example, there are about 500,000 neurons in mouse V1, so in this case we are measuring around 0.02% of the firing rates in this region.\n",
    "\n",
    "As the number of simultaneously recorded neurons increases, we expect that our ability to decode stimulus identity will improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82b8f8",
   "metadata": {},
   "source": [
    "To start with, let's try decoding with a random sample of 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3502d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 10\n",
    "\n",
    "pop_idx = np.random.choice(range(num_units), size=pop_size)\n",
    "responses_pop = responses[:, pop_idx]\n",
    "\n",
    "accuracies = []\n",
    "accuracies_hit = []\n",
    "accuracies_miss = []\n",
    "\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses_pop[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses_pop[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) \n",
    "\n",
    "        \n",
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b48d81",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "Does the result depend on which 10 neurons we sampled? Let's try another random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58550b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_idx = np.random.choice(range(num_units), size=pop_size)\n",
    "responses_pop = responses[:, pop_idx]\n",
    "\n",
    "accuracies = []\n",
    "accuracies_hit = []\n",
    "accuracies_miss = []\n",
    "\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses_pop[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses_pop[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) \n",
    "\n",
    "        \n",
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1967ae",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "### Now, let's try to get a sense for how this changes with the number of neurons we use to train the classifier. \n",
    "    \n",
    "### How many neurons do you need to decode with roughly 50% accuracy? 80%? 90%? Finish the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_sizes = np.arange(1, num_units+5, 5).astype('int')\n",
    "num_resamples = 10\n",
    "\n",
    "accuracies = np.zeros((len(pop_sizes), num_resamples, num_splits))\n",
    "accuracies_hit = np.zeros((len(pop_sizes), num_resamples, num_splits))\n",
    "accuracies_miss = np.zeros((len(pop_sizes), num_resamples, num_splits))\n",
    "\n",
    "for i, pop_size in enumerate(pop_sizes):\n",
    "    print('population size: {}'.format(pop_size))\n",
    "\n",
    "    for j in range(num_resamples):\n",
    "        pop_idx = np.random.choice(range(num_units), size=pop_size)\n",
    "        responses_pop = responses[:, pop_idx]\n",
    "            \n",
    "        k = 0\n",
    "        for train_indices, test_indices in KFold(n_splits=num_splits, shuffle=True).split(responses):\n",
    "            clf = svm.SVC()\n",
    "            clf.fit(responses_pop[train_indices], labels[train_indices])\n",
    "\n",
    "            test_targets = labels[test_indices]\n",
    "            test_predictions = clf.predict(responses_pop[test_indices])\n",
    "\n",
    "            accuracies[i, j, k] = np.mean(test_targets == test_predictions)        \n",
    "\n",
    "            test_hit = hit[test_indices].astype('bool')\n",
    "            test_miss = miss[test_indices].astype('bool')\n",
    "\n",
    "            accuracies_hit[i, j, k] = np.mean(test_targets[test_hit] == test_predictions[test_hit])\n",
    "            accuracies_miss[i, j, k] = np.mean(test_targets[test_miss] == test_predictions[test_miss])\n",
    "\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=pop_sizes, y=accuracies.mean(axis=(1, 2)), yerr=accuracies.std(axis=(1, 2)), fmt='o-')\n",
    "\n",
    "plt.xlabel('Population size')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af6368",
   "metadata": {},
   "source": [
    "Roughly how many neurons do you need to decode with 50% accuracy? 80%? 90%?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de54b31",
   "metadata": {},
   "source": [
    "# With these analyses in hand, we leave you with some questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63c00a",
   "metadata": {},
   "source": [
    "### If you integrate spikes in a fixed window length, how does the decoding accuracy depend on the time since the image presentation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7a1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7626587d",
   "metadata": {},
   "source": [
    "### Where do the lick time distributions fall on the decoding accuracy vs time curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480cbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167e64c4",
   "metadata": {},
   "source": [
    "### Is the mouse's hit rate different for familiar or novel change images? Is the change decoding accuracy curve different for familiar vs novel change images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce64c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e511b6cf",
   "metadata": {},
   "source": [
    "### Are the accuracy curves different in active vs passive blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0b507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a628ae2",
   "metadata": {},
   "source": [
    "### Are other variables, including behavioral variables, also encoded in the population activity? Can you decode the running speed, pupil diameter, or licking behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d885d65d",
   "metadata": {},
   "source": [
    "### What about in a different brain area? For example, is the change encoded in CA1 activity? What about in the joint activity across brain areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c273d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
